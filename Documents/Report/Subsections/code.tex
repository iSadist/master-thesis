\newpage

\begin{appendices}
\chapter{Code from chapter Augmented Reality}
\section{}
\begin{lstlisting}[language=swift]
func loadWorldTrackingConfiguration()
    {
        let configuration = ARWorldTrackingConfiguration()
        configuration.planeDetection = [.horizontal]

        // All the objects that are tracked is contained in the Objects folder
        guard let detectingObjects = ARReferenceObject.referenceObjects(inGroupNamed: "Objects", bundle: nil) else { return }
        configuration.detectionObjects = detectingObjects
        
        // Setting up tracking of images
        for imageURL in trackingImageURLs
        {
            guard let image: CGImage = UIImage(named: imageURL)?.cgImage else { return }
            let referenceImage = ARReferenceImage(image, orientation: CGImagePropertyOrientation.up, physicalWidth: 0.3)
            configuration.detectionImages.insert(referenceImage)
        }

        configuration.maximumNumberOfTrackedImages = trackingImageURLs.count
        
        // Running the sessoin with the configuration
        sceneView.session.run(configuration)
    }
\end{lstlisting}

\section{}
\begin{lstlisting}[language=swift]
// Load the scene
let scene = SCNScene(named: "art.scnassets/world.scn")!        
sceneView.scene = scene
\end{lstlisting}

\section{}

\begin{lstlisting}[language=swift]
func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor)
    {
    	    // If detected an object
        if let objectAnchor = anchor as? ARObjectAnchor
        {
        	   // Add some 3D text to the scene
            let objectName = objectAnchor.referenceObject.name!
            let textNode = GeometryFactory.makeText(text: objectName)
            node.addChildNode(textNode)
        }
        // If detected a plane
        else if let planeAnchor = anchor as? ARPlaneAnchor
        {
        // Add a plane geometry of the detected floor to the scene
        node.addChildNode(GeometryFactory.createPlane(planeAnchor: planeAnchor, metalDevice: metalDevice!))
            model.numberOfPlanesDetected += 1
        }
    }
\end{lstlisting}

If nodes need to be rendered outside of this function it can be done by accessing the
scenes root node.

\begin{lstlisting}[language=swift]
sceneView.scene.rootNode.addChildNode(node)
\end{lstlisting}

\chapter{Code from chapter neural networks}
\section{}
\begin{lstlisting}[language=python]
#Python script from training
#Project path:
	master-thesis/Training/trainer.py
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.utils import shuffle

train_images = []
train_labels = []
loadImages(train_images, train_labels, "Train", 200)
train_images = reshapeArray(train_images)

test_images = []
test_labels = []
loadImages(test_images, test_labels, "Test", 39)
test_images = reshapeArray(test_images)

# Create the neural network
model = keras.Sequential([
	keras.layers.Conv2D(4, kernel_size=(5, 5), strides=(2, 2), input_shape=(image_height, image_width, number_of_color_channels)),
		
	["The code for the hidden layers"]

	keras.layers.Dense(4, activation=tf.nn.softmax)
])

model.compile(optimizer=keras.optimizers.Adam(),
	    loss='sparse_categorical_crossentropy',
	    metrics=['accuracy'])
	    
train_data, train_labels = shuffle(train_data, train_labels)

early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1)
checkpoint = keras.callbacks.ModelCheckpoint("./Models/Nolmyra.h5", monitor='val_acc', 
verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)

history = model.fit(train_data, train_labels, epochs=40, batch_size=10, validation_data=(test_images, test_labels), callbacks=[early_stopping, checkpoint] , verbose=1)

model.save("./Models/recognizer.h5")
\end{lstlisting}

\section{}
\begin{lstlisting}[language=python]
Conv2D(4, kernel_size=(5, 5), strides=(2, 2), input_shape=(image_height, image_width, number_of_color_channels)),
Conv2D(4, kernel_size=(3, 3), strides=(1, 1), input_shape=(image_height, image_width, number_of_color_channels)),
MaxPool2D(pool_size=(2, 2), padding="valid"),
BatchNormalization(),
LeakyReLU(),
Conv2D(8, kernel_size=(3, 3), strides=(1, 1)),
Conv2D(8, kernel_size=(3, 3), strides=(1, 1)),
Conv2D(8, kernel_size=(3, 3), strides=(1, 1)),
MaxPool2D(pool_size=(2, 2), padding="valid"),
BatchNormalization(),
LeakyReLU(),
Conv2D(16, kernel_size=(3, 3), strides=(1, 1)),
Conv2D(16, kernel_size=(3, 3), strides=(1, 1)),
Conv2D(16, kernel_size=(3, 3), strides=(1, 1)),
MaxPool2D(pool_size=(2, 2), padding="valid"),
BatchNormalization(),
LeakyReLU(),
Flatten(),
Dropout(0.5),
Dense(64, kernel_regularizer=keras.regularizers.l2(0.003), activation=tf.nn.relu),
GaussianNoise(0.2),
Dense(64, kernel_regularizer=keras.regularizers.l2(0.003), activation=tf.nn.relu),
Dropout(0.25),
Dense(4, activation=tf.nn.softmax)
\end{lstlisting}

\section{}
 \begin{lstlisting}[language=python]
#Project path: master-thesis/FeatureTraining/transferLearning.py
from keras import applications
from keras.preprocessing.image import ImageDataGenerator
from keras import optimizers
from keras.models import Sequential, Model
from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Input, Conv2D, MaxPool2D
from keras import backend as k
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping

#Load data and pretrained model
img_width, img_height = 256, 256
train_data_dir = "data/train"
validation_data_dir = "data/val"
nb_train_samples = 129
nb_validation_samples = 21
batch_size = 16
epochs = 50
input_layer = Input(shape=(256,256,3))
model = applications.VGG16(include_top=False, weights='imagenet', input_tensor=input_layer, pooling=None)

#Cut network and add own layers
x = model.get_layer('block5_pool').output
x = Flatten()(x)
x = Dense(512, activation="relu")(x)
predictions = Dense(4, activation="softmax")(x)

# creating the composed model
model_final = Model(inputs = model.input, outputs = predictions)
for layer in model_final.layers[:-2]:
    layer.trainable = False
    
# compile the model
model_final.compile(loss = "categorical_crossentropy", optimizer = optimizers.SGD(lr = 0.0001, momentum = 0.9), metrics=["accuracy"])

#Hidden lines of code
.........

#Train the model
hist = model_final.fit_generator(
train_generator,
epochs = epochs,
validation_data = validation_generator,
callbacks = [checkpoint, early])
\end{lstlisting}

\end{appendices}
